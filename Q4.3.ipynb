{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To install OpenCV: type \"conda install opencv\" on terminal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from skimage.feature import corner_harris, corner_peaks\n",
    "from sklearn import linear_model\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.measure import ransac\n",
    "from skimage.util.shape import view_as_windows\n",
    "from numpy.linalg import norm as normalize\n",
    "import cv2\n",
    "\n",
    "if not os.path.exists(\"Q4\"):\n",
    "    os.makedirs(\"Q4\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.3 (a) - Finding Matching Points (SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    chapel1 = cv2.imread('Files/chapel1.png',0)\n",
    "    chapel2 = cv2.imread('Files/chapel2.png',0) \n",
    "\n",
    "    sift = cv2.SIFT()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(chapel1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(chapel2,None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "    \n",
    "    chapel1 = cv2.cvtColor(chapel1,cv2.COLOR_GRAY2BGR)\n",
    "    chapel2 = cv2.cvtColor(chapel2,cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "    \n",
    "    for pt1, pt2 in zip(pts1,pts2): \n",
    "        x1,y1 = pt1\n",
    "        cv2.circle(chapel1,(x1,y1),2,(0,0,255),-1)\n",
    "        x2,y2 = pt2\n",
    "        cv2.circle(chapel2,(x2,y2),2,(0,0,255),-1)\n",
    "\n",
    "    # Plotting matched points on figure\n",
    "    plt.imshow(chapel1)\n",
    "    fn = 'chapel1_SIFT.png'\n",
    "    plt.savefig('Q4/' + fn, dpi=200)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.imshow(chapel2)\n",
    "    fn = 'chapel2_SIFT.png'\n",
    "    plt.savefig('Q4/' + fn, dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.3 (b) - Estimating Fundamental Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RANSAC **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Finding Fundamental Matrix, Inliers and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts1 = np.float32(pts1)\n",
    "pts2 = np.float32(pts2)    \n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_RANSAC)\n",
    "   \n",
    "#Keep record of outlier points\n",
    "outliers1 = pts1[mask.ravel()==0]\n",
    "outliers2 = pts2[mask.ravel()==0]\n",
    "\n",
    "#Select only inlier points\n",
    "pts1 = pts1[mask.ravel()==1]\n",
    "pts2 = pts2[mask.ravel()==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Normalizing Fundamental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamental Matrix :\n",
      "[[ -1.41310716e-07   1.23557572e-04  -1.69133474e-02]\n",
      " [ -1.18458902e-04  -3.44997180e-06  -4.69073921e-02]\n",
      " [  1.73720033e-02   4.35977543e-02   1.00000000e+00]]\n",
      "\n",
      "\n",
      "Normalized Fundamental Matrix :\n",
      "[[ -1.40980578e-07   1.23268909e-04  -1.68738334e-02]\n",
      " [ -1.18182151e-04  -3.44191177e-06  -4.67978043e-02]\n",
      " [  1.73314178e-02   4.34958986e-02   9.97663740e-01]]\n"
     ]
    }
   ],
   "source": [
    "print \"Fundamental Matrix :\" \n",
    "print F\n",
    "print \"\\n\"\n",
    "\n",
    "F = np.array(F)\n",
    "norm = normalize(F)\n",
    "F_norm = np.zeros(F.shape)\n",
    "\n",
    "for i in range(len(F)):\n",
    "    for j in range(len(F[i])):\n",
    "        F_norm[i][j] = F[i][j]/norm\n",
    "        \n",
    "print \"Normalized Fundamental Matrix :\"\n",
    "print F_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) Plotting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chapel1 = cv2.imread('Files/chapel1.png')\n",
    "chapel2 = cv2.imread('Files/chapel2.png')\n",
    "\n",
    "outliers1 = np.int32(outliers1)\n",
    "outliers2 = np.int32(outliers2)\n",
    "\n",
    "for i in  range(len(outliers1)):\n",
    "            \n",
    "    x1,y1 = outliers1[i]\n",
    "    cv2.circle(chapel1,(x1,y1),3,(0,255,0),-1)\n",
    "    \n",
    "    x2,y2 = outliers2[i]\n",
    "    cv2.circle(chapel2,(x1,y2),3,(0,255,0),-1)\n",
    "        \n",
    "    plt.imshow(chapel1)\n",
    "    fn = 'chapel1_outliers.png'\n",
    "    plt.savefig('Q4/' + fn, dpi=200)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.imshow(chapel2)\n",
    "    fn = 'chapel2_outliers.png'\n",
    "    plt.savefig('Q4/' + fn, dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.3 (c) - Drawing Epipolar Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function draws the first 7 epilines on img1 based on the points in img2; lines = corresponding epilines\n",
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "\n",
    "    r,c,_ = img1.shape\n",
    "    \n",
    "    for i in range(7):\n",
    "        n = random.randint(0,len(pts1))\n",
    "        #color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -lines[n][2]/lines[n][1] ])\n",
    "        x1,y1 = map(int, [c, -(lines[n][2]+lines[n][0]*c)/lines[n][1] ])\n",
    "        cv2.line(img1, (x0,y0), (x1,y1), (255,0,0),1)\n",
    "        cv2.circle(img1,tuple(np.int32(pts1[n])),3,(0,255,0),-1)\n",
    "        cv2.circle(img2,tuple(np.int32(pts2[n])),3,(0,255,0),-1)\n",
    "    return img1,img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chapel1 = cv2.imread('Files/chapel1.png')\n",
    "chapel2 = cv2.imread('Files/chapel2.png')\n",
    "\n",
    "# Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "\n",
    "lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F_norm)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "img5,img6 = drawlines(chapel1,chapel2,lines1,pts1,pts2)\n",
    "\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F_norm)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "img3,img4 = drawlines(chapel2,chapel1,lines2,pts2,pts1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121), plt.imshow(img5)\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(122), plt.imshow(img3)\n",
    "plt.axis('off')\n",
    "fig.savefig('Q4/epiline.png', dpi = 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix (unused)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HarrisCornerCV(frame, numCorners, quality, minDist):\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    #dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "    #img[dst>0.01*dst.max()]=[0,0,255]\n",
    "    #cv2.imshow('dst',img)\n",
    "    corners = cv2.goodFeaturesToTrack(gray, numCorners, quality, minDist)\n",
    "    corners = np.int0(corners)\n",
    "    \n",
    "    return corners\n",
    "\n",
    "# this function creates an image patch with size LxL centered at coord. \n",
    "# NOTE: L must be odd, so that centre of window can be at coord\n",
    "def CreatePatch(coord, img, L):\n",
    "    window = view_as_windows(img, (L,L))\n",
    "    patch = window[coord[1] - L/2, coord[0] - L/2]    \n",
    "    \n",
    "    return patch\n",
    "\n",
    "# this function creates a search window of size LxL centered at refCoord, and returns all feature points in \n",
    "# non-stabilized image that are within that window\n",
    "# NOTE: L must be odd, so that centre of window can be at coord\n",
    "def SearchFP(refCoord,imgFP,L):\n",
    "    searchedFP = []\n",
    "    for imgCoord in imgFP:\n",
    "        if abs(imgCoord[0]-refCoord[0]) <= L/2 and abs(imgCoord[1]-refCoord[1]) <= L/2:\n",
    "            searchedFP.append(imgCoord)\n",
    "            \n",
    "    return searchedFP\n",
    "\n",
    "# this function creates template matching of 2 images and output the min value of SSD\n",
    "def TemplateMatchSSD(img, template):\n",
    "    method = eval('cv2.TM_SQDIFF')\n",
    "\n",
    "    # Apply template Matching\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    \n",
    "    return min_val\n",
    "            \n",
    "    from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Matched FPs found\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = 'Files/'\n",
    "    imagelist = []\n",
    "\n",
    "    # reading images and storing filename\n",
    "    for filename in glob.glob(os.path.join(path, '*.png')): \n",
    "        im = cv2.imread(filename)\n",
    "        fn = filename.split('/')[-1].split('.')[0]\n",
    "        imagelist.append((fn, im))\n",
    "\n",
    "    refFP, imgFP = [], []\n",
    "    refFilename, refFrame = imagelist[0]\n",
    "    refGray = cv2.cvtColor(refFrame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Creating Feature Points for Reference Image (chapel 1)\n",
    "    corners = HarrisCornerCV(refFrame, 100, 0.01, 10)\n",
    "    for i in corners:\n",
    "        x,y = i.ravel()\n",
    "        refFP.append([x,y])\n",
    "    \n",
    "    # Creating array of Matched Feature Points for and drawing all Matched Feature Points in Q4 folder \n",
    "    filename, frame = imagelist[1]\n",
    "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # Creating Feature Points for Non-Stabilised Image\n",
    "    corners = HarrisCornerCV(frame, 100, 0.01, 10)\n",
    "    for i in corners:\n",
    "        x,y = i.ravel()\n",
    "        imgFP.append([x,y])\n",
    "    \n",
    "    matchedCoord = [] # array to store matched feature points\n",
    "        \n",
    "    for refCoord in refFP:\n",
    "        # Finding feature points in non-stabilised image that are within search window\n",
    "        searchedFP = SearchFP(refCoord, imgFP, 15) #window bigger than min_dist between FP\n",
    "        if len(searchedFP) == 0:\n",
    "             continue # if no feature points were found in search window, don't register refCoord to matchedCoord\n",
    "        else:    \n",
    "            template = CreatePatch(refCoord, refGray, 10)\n",
    "            SSD = [] # array to store SSD of searchedPatch vs stabilised image patch\n",
    "            for searchedCoord in searchedFP:\n",
    "                img = CreatePatch(searchedCoord, imgGray,10)\n",
    "                min_val = TemplateMatchSSD(img, template)\n",
    "                SSD.append(min_val)\n",
    "                \n",
    "            # matching ref FP to with FP in non-stabilised image\n",
    "            SSD = np.array(SSD)\n",
    "            idx = np.argmin(SSD)\n",
    "            matchedCoord.append([refCoord, searchedFP[idx]])\n",
    "        \n",
    "    print str(len(matchedCoord)) + \" Matched FPs found\"\n",
    "        \n",
    "    for i in range(len(matchedCoord)):\n",
    "            \n",
    "        xR,yR = matchedCoord[i][0]\n",
    "        cv2.circle(refFrame,(xR,yR),3,(0,0,255),-1)\n",
    "        xI,yI = matchedCoord[i][1]\n",
    "        cv2.circle(frame,(xI,yI),3,(0,0,255),-1)\n",
    "     \n",
    "    plt.imshow(frame)\n",
    "    fn = 'chapel2_autoMatch.png'\n",
    "    plt.savefig('Q4/' + fn, dpi=200)\n",
    "    plt.close()\n",
    "        \n",
    "    plt.imshow(refFrame)\n",
    "    fn = 'chapel1_autoMatch.png'\n",
    "    plt.savefig('Q4/' + fn, dpi=200)\n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pts1, pts2 = [], []\n",
    "\n",
    "put chapel1.jpg feature points into pts1, and chapel2.jpg feature points into pts2\n",
    "for row in matchedCoord:\n",
    "    pts1.append(row[0])\n",
    "    pts2.append(row[1])\n",
    "    \n",
    "pts1 = np.float32(pts1)\n",
    "pts2 = np.float32(pts2)    \n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_RANSAC)\n",
    "   \n",
    "#Keep record of outlier points\n",
    "outliers1 = pts1[mask.ravel()==0]\n",
    "outliers2 = pts2[mask.ravel()==0]\n",
    "\n",
    "#Select only inlier points\n",
    "pts1 = pts1[mask.ravel()==1]\n",
    "pts2 = pts2[mask.ravel()==1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
